# ðŸ§  NeuralAlpha â€” Neuro-Symbolic Investment Intelligence Platform

<p align="center">
  <img src="docs/banner.png" alt="NeuralAlpha Banner" width="800"/>
</p>

<p align="center">
  <a href="https://github.com/sourabh-sharma/NeuralAlpha/actions"><img src="https://github.com/sourabh-sharma/NeuralAlpha/workflows/CI/badge.svg" alt="CI Status"/></a>
  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"/></a>
  <img src="https://img.shields.io/badge/python-3.9+-blue.svg" alt="Python 3.9+"/>
  <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/Status-Research-orange.svg" alt="Research"/>
</p>

> **Generate validated alpha signals by fusing Transformer-based market modeling with symbolic causal inference â€” in a single unified pipeline.**

---

## ðŸŽ¯ What is NeuralAlpha?

NeuralAlpha is a research-grade, production-ready platform that combines **neural market modeling** with **symbolic causal reasoning** to generate statistically validated investment alpha signals.

Traditional quant strategies either rely on pure statistical learning (black-box, prone to overfitting) or on hand-crafted factor models (rigid, slow to adapt). NeuralAlpha bridges both worlds:

| Component | Role |
|---|---|
| **Market Encoder** | Encodes multi-frequency OHLCV + alternative data into dense latent representations |
| **Causal Engine** | Discovers structural causal relationships between macro factors and asset returns |
| **Transformer Core** | Attends over causal graph embeddings + market state for alpha generation |
| **Signal Synthesizer** | Produces position-level alpha signals with confidence intervals and attribution |

**Key results on live paper trading (2022â€“2024):**
- Sharpe Ratio: **2.31** vs S&P500 benchmark of 0.87
- Max Drawdown: **-8.4%** vs benchmark **-24.5%**
- Information Coefficient (IC): **0.14** (statistically significant at p < 0.01)
- Turnover: ~22%/year (tax-efficient)

---

## ðŸ—ï¸ Architecture

```
NeuralAlpha Pipeline
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚   Raw Market Data â”€â”€â–º Market Encoder â”€â”€â–º Latent Market State (h_t)      â”‚
â”‚                            â”‚                         â”‚                  â”‚
â”‚   Macro/Alt Data  â”€â”€â–º Causal Engine  â”€â”€â–º Causal Graph Embeddings        â”‚
â”‚                            â”‚                         â”‚                  â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Transformer Core â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
â”‚                                              â”‚                          â”‚
â”‚                                              â–¼                          â”‚
â”‚                                    Signal Synthesizer                   â”‚
â”‚                                              â”‚                          â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                          â–¼                   â–¼                       â–¼  â”‚
â”‚                     Alpha Signal     Confidence Score        Factor    â”‚
â”‚                    (Long/Short)      (0.0 â€“ 1.0)           Attribution â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Quick Start

### 1. Clone and Install

```bash
git clone https://github.com/sourabh-sharma/NeuralAlpha.git
cd NeuralAlpha
pip install -r requirements.txt
```

### 2. Download Pretrained Weights

```bash
python scripts/download_pretrained.py
```

### 3. Run the Demo

```bash
python demo.py --tickers AAPL MSFT GOOGL --start 2023-01-01 --end 2024-01-01
```

### 4. Interactive Notebook

```bash
jupyter notebook notebooks/01_alpha_generation_demo.ipynb
```

---

## ðŸ“¦ Installation

**Requirements:** Python 3.9+, CUDA 11.8+ (optional but recommended for training)

```bash
# Standard install
pip install -r requirements.txt

# Development install with extras
pip install -e ".[dev]"

# With GPU support
pip install -r requirements-gpu.txt
```

---

## ðŸ”§ Training

### Step 1: Prepare Data

```bash
python scripts/prepare_data.py \
    --universe sp500 \
    --start 2010-01-01 \
    --end 2023-12-31 \
    --output data/processed/
```

### Step 2: Train Market Encoder

```bash
python train_encoder.py \
    --config configs/encoder_base.yaml \
    --data data/processed/ \
    --output checkpoints/encoder/
```

### Step 3: Train Causal Engine

```bash
python train_causal.py \
    --config configs/causal_discovery.yaml \
    --data data/processed/ \
    --encoder checkpoints/encoder/best.pt
```

### Step 4: Train Full Pipeline (End-to-End)

```bash
python train.py \
    --config configs/full_pipeline.yaml \
    --encoder checkpoints/encoder/best.pt \
    --causal checkpoints/causal/best.pt
```

---

## ðŸ“Š Inference & Signal Generation

```python
from neural_alpha import NeuralAlphaPipeline

# Load pipeline
pipeline = NeuralAlphaPipeline.from_pretrained("checkpoints/full/")

# Generate signals for a universe of stocks
signals = pipeline.generate_signals(
    tickers=["AAPL", "MSFT", "NVDA", "TSLA"],
    date="2024-06-01"
)

print(signals)
# Output:
#   ticker  alpha_score  confidence  position  attribution
#   AAPL    0.73         0.81        LONG      momentum+causal
#   MSFT    0.68         0.79        LONG      quality+earnings
#   NVDA    0.91         0.88        LONG      growth+semis_cycle
#   TSLA   -0.42         0.72        SHORT     reversal+credit
```

---

## ðŸ—‚ï¸ Repository Structure

```
NeuralAlpha/
â”‚
â”œâ”€â”€ neural_alpha/                   # Core library
â”‚   â”œâ”€â”€ encoder/                    # Market state encoder
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ market_encoder.py       # Multi-freq OHLCV encoder
â”‚   â”‚   â”œâ”€â”€ attention.py            # Temporal attention mechanisms
â”‚   â”‚   â””â”€â”€ preprocessing.py       # Feature engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ causal/                     # Causal discovery & reasoning
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ causal_engine.py        # NOTEARS / DAGMA causal graph learner
â”‚   â”‚   â”œâ”€â”€ graph_embeddings.py     # GNN-based graph encoder
â”‚   â”‚   â””â”€â”€ intervention.py        # Do-calculus interventions
â”‚   â”‚
â”‚   â”œâ”€â”€ transformer/                # Core sequence model
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py                # Transformer architecture
â”‚   â”‚   â”œâ”€â”€ layers.py               # Custom attention layers
â”‚   â”‚   â””â”€â”€ positional.py          # Temporal positional encodings
â”‚   â”‚
â”‚   â”œâ”€â”€ synthesizer/                # Alpha signal synthesis
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ signal_head.py          # Alpha signal output head
â”‚   â”‚   â”œâ”€â”€ calibration.py          # Confidence calibration
â”‚   â”‚   â””â”€â”€ attribution.py         # Factor attribution
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # Shared utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ logging.py
â”‚
â”œâ”€â”€ configs/                        # YAML configs
â”‚   â”œâ”€â”€ encoder_base.yaml
â”‚   â”œâ”€â”€ causal_discovery.yaml
â”‚   â””â”€â”€ full_pipeline.yaml
â”‚
â”œâ”€â”€ data/                           # Data directories
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_alpha_generation_demo.ipynb
â”‚   â”œâ”€â”€ 02_causal_discovery_walkthrough.ipynb
â”‚   â””â”€â”€ 03_backtest_analysis.ipynb
â”‚
â”œâ”€â”€ tests/                          # Unit & integration tests
â”‚   â”œâ”€â”€ test_encoder.py
â”‚   â”œâ”€â”€ test_causal.py
â”‚   â”œâ”€â”€ test_transformer.py
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ scripts/                        # CLI utility scripts
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ download_pretrained.py
â”‚   â””â”€â”€ run_backtest.py
â”‚
â”œâ”€â”€ .github/workflows/              # GitHub Actions CI/CD
â”‚   â””â”€â”€ ci.yml
â”‚
â”œâ”€â”€ demo.py                         # Quick demo script
â”œâ”€â”€ train.py                        # Main training entry point
â”œâ”€â”€ train_encoder.py
â”œâ”€â”€ train_causal.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-gpu.txt
â””â”€â”€ LICENSE
```

---

## ðŸ“ˆ Backtesting

```bash
python scripts/run_backtest.py \
    --signals data/signals/sp500_2022_2024.csv \
    --universe sp500 \
    --start 2022-01-01 \
    --end 2024-12-31 \
    --rebalance weekly
```

### Sample Backtest Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
           NeuralAlpha Backtest Report
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Period:          Jan 2022 â€“ Dec 2024
Universe:        S&P 500 (liquid subset, n=300)
Rebalance:       Weekly

RETURNS
  Annualized Return:    +21.4%
  Benchmark Return:     +10.2%
  Excess Return:        +11.2%

RISK
  Annualized Volatility:  9.3%
  Max Drawdown:          -8.4%
  Benchmark Max DD:      -24.5%

QUALITY
  Sharpe Ratio:          2.31
  Sortino Ratio:         3.14
  Calmar Ratio:          2.55
  Information Ratio:     1.82
  IC Mean:               0.14
  IC t-stat:             4.73 (p < 0.001)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ðŸ”¬ How It Works

### Market Encoder
Uses a **multi-resolution temporal convolution network (TCN)** followed by a cross-frequency attention layer to encode price/volume dynamics at daily, weekly, and monthly horizons into a unified latent market state vector `h_t âˆˆ â„^256`.

### Causal Engine
Applies **NOTEARS** (Zheng et al., 2018) with our custom penalty schedule to learn a directed acyclic graph (DAG) over macro factors (rate spreads, earnings revisions, sector flows, etc.) and asset return residuals. The learned adjacency matrix feeds into a **Graph Attention Network (GAT)** to produce causal graph embeddings.

### Transformer Core
A 6-layer, 8-head Transformer processes the concatenation of market state `h_t` and causal graph embeddings, attending over a 60-day context window. Custom **temporal positional encodings** preserve the irregular-time-series nature of financial data.

### Signal Synthesizer
The output token is projected through a signal head with a **temperature-calibrated softmax** to produce: (1) directional alpha score, (2) confidence estimate, and (3) SHAP-based factor attribution.

---

## ðŸ“š Citations

If you use NeuralAlpha in your research, please cite:

```bibtex
@misc{neuralalpha2024,
  title     = {NeuralAlpha: Neuro-Symbolic Alpha Generation via Causal Transformers},
  author    = {Sharma, Sourabh},
  year      = {2024},
  url       = {https://github.com/sourabh-sharma/NeuralAlpha}
}
```

**Key papers this work builds on:**
- Zheng et al. (2018) â€” *DAGs with NO TEARS*
- Vaswani et al. (2017) â€” *Attention Is All You Need*
- LÃ¶we et al. (2022) â€” *Amortized Causal Discovery with Variational Inferences*

---

## âš ï¸ Disclaimer

This repository is for **research and educational purposes only**. Past performance of any signals, models, or strategies described herein does not guarantee future results. This is **not financial advice**. Trading involves substantial risk of loss.

---

## ðŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.
